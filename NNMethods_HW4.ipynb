{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Neural Networks in NLP HW 4","metadata":{}},{"cell_type":"markdown","source":"## Дарья Родионова","metadata":{}},{"cell_type":"code","source":"! pip install -q -U watermark","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:07:12.337392Z","iopub.execute_input":"2022-03-24T21:07:12.337966Z","iopub.status.idle":"2022-03-24T21:07:23.706818Z","shell.execute_reply.started":"2022-03-24T21:07:12.337848Z","shell.execute_reply":"2022-03-24T21:07:23.705979Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nmarkdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 2.1.3 which is incompatible.\nkeyring 23.4.0 requires importlib-metadata>=3.6, but you have importlib-metadata 2.1.3 which is incompatible.\nibis-framework 2.1.1 requires importlib-metadata<5,>=4; python_version < \"3.8\", but you have importlib-metadata 2.1.3 which is incompatible.\ngym 0.23.1 requires importlib-metadata>=4.10.0; python_version < \"3.10\", but you have importlib-metadata 2.1.3 which is incompatible.\narviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.1.1 which is incompatible.\u001b[0m\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install transformers","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:08:09.634888Z","iopub.execute_input":"2022-03-24T21:08:09.635162Z","iopub.status.idle":"2022-03-24T21:08:17.445694Z","shell.execute_reply.started":"2022-03-24T21:08:09.635128Z","shell.execute_reply":"2022-03-24T21:08:17.444797Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.16.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.20.3)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.49)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.26.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (2.1.3)\nRequirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.11.6)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.4.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.6)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.6.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.7)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.9)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"%reload_ext watermark\n%watermark -v -p numpy,pandas,torch,transformers","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:08:39.630157Z","iopub.execute_input":"2022-03-24T21:08:39.630689Z","iopub.status.idle":"2022-03-24T21:08:42.517074Z","shell.execute_reply.started":"2022-03-24T21:08:39.630651Z","shell.execute_reply":"2022-03-24T21:08:42.515820Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Python implementation: CPython\nPython version       : 3.7.12\nIPython version      : 7.30.1\n\nnumpy       : 1.20.3\npandas      : 1.3.5\ntorch       : 1.9.1\ntransformers: 4.16.2\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Скачиваем нужные модули.","metadata":{}},{"cell_type":"code","source":"import transformers\nfrom transformers import BertModel, AutoModel,AutoTokenizer, BertTokenizer, PreTrainedTokenizerFast, AdamW, get_linear_schedule_with_warmup\nimport torch.nn.functional as F\n\nimport torch\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom collections import defaultdict\nfrom textwrap import wrap\nfrom torch import nn, optim\nfrom torch.nn.utils import clip_grad_norm_\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:08:56.170986Z","iopub.execute_input":"2022-03-24T21:08:56.171364Z","iopub.status.idle":"2022-03-24T21:09:06.462859Z","shell.execute_reply.started":"2022-03-24T21:08:56.171326Z","shell.execute_reply":"2022-03-24T21:09:06.461828Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n%config InlineBackend.figure_format='retina'\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\nHAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\nsns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\nrcParams['figure.figsize'] = 8, 6","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:09:09.227001Z","iopub.execute_input":"2022-03-24T21:09:09.227993Z","iopub.status.idle":"2022-03-24T21:09:09.264465Z","shell.execute_reply.started":"2022-03-24T21:09:09.227941Z","shell.execute_reply":"2022-03-24T21:09:09.263366Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"! pip install datasets","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:09:11.545023Z","iopub.execute_input":"2022-03-24T21:09:11.546074Z","iopub.status.idle":"2022-03-24T21:09:23.764696Z","shell.execute_reply.started":"2022-03-24T21:09:11.546015Z","shell.execute_reply":"2022-03-24T21:09:23.763447Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (1.18.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.4.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.4)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.12.2)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.62.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.20.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (21.3)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (2.1.3)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.26.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (3.0.6)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.0.9)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (5.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.2.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.6.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2021.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Downloading Data","metadata":{}},{"cell_type":"markdown","source":"Загружаем данные и делим их сразу на train/val/test.","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\nimdb_datasets = load_dataset('imdb', \n                             split={'train': 'train[:2000]+train[-2000:]', \n                                    'test': 'test[:1000]+test[-1000:]', \n                                    'validation': 'test[1000:2000]+test[-2000:-1000]'})","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:09:27.677341Z","iopub.execute_input":"2022-03-24T21:09:27.678890Z","iopub.status.idle":"2022-03-24T21:10:25.761752Z","shell.execute_reply.started":"2022-03-24T21:09:27.678797Z","shell.execute_reply":"2022-03-24T21:10:25.760749Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d71be9588dbf465ea0059d98e67374ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"259d3a0e71ab415cadf244779eec87d0"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset imdb/plain_text (download: 80.23 MiB, generated: 127.02 MiB, post-processed: Unknown size, total: 207.25 MiB) to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/84.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed2be9ad7c0e4096bd292ce6575bdfbc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset imdb downloaded and prepared to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45a351fcd04c4f92a50dd149ec95a726"}},"metadata":{}}]},{"cell_type":"code","source":"imdb_datasets","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:10:28.845946Z","iopub.execute_input":"2022-03-24T21:10:28.846815Z","iopub.status.idle":"2022-03-24T21:10:28.874572Z","shell.execute_reply.started":"2022-03-24T21:10:28.846714Z","shell.execute_reply":"2022-03-24T21:10:28.872292Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 4000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n    validation: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"Решила выбрать модель bert-small, так как она маленькая и быстрая. ","metadata":{}},{"cell_type":"code","source":"MODEL_NAME = 'prajjwal1/bert-small'","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:10:31.605168Z","iopub.execute_input":"2022-03-24T21:10:31.606195Z","iopub.status.idle":"2022-03-24T21:10:31.617075Z","shell.execute_reply.started":"2022-03-24T21:10:31.606138Z","shell.execute_reply":"2022-03-24T21:10:31.615902Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:10:33.744737Z","iopub.execute_input":"2022-03-24T21:10:33.745563Z","iopub.status.idle":"2022-03-24T21:10:46.056459Z","shell.execute_reply.started":"2022-03-24T21:10:33.745474Z","shell.execute_reply":"2022-03-24T21:10:46.055368Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/286 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb942ff5e5ec41b7a9d5b299ec4a2837"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"452998586a834f07af209d662def3ee2"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Preprocessing","metadata":{}},{"cell_type":"markdown","source":"Токенизируем данные. ","metadata":{}},{"cell_type":"code","source":"def preprocess(texts, tokenizer):\n    result = tokenizer(texts['text'], \n                       max_length=512, \n                       padding='max_length', \n                       truncation=True)\n    \n    result['label'] = texts['label']\n    \n    return result","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:10:57.837995Z","iopub.execute_input":"2022-03-24T21:10:57.838319Z","iopub.status.idle":"2022-03-24T21:10:57.848567Z","shell.execute_reply.started":"2022-03-24T21:10:57.838285Z","shell.execute_reply":"2022-03-24T21:10:57.845426Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from functools import partial\n\ntokenized_datasets = imdb_datasets.map(\n    partial(preprocess, tokenizer=tokenizer),\n    batched=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:11:00.395963Z","iopub.execute_input":"2022-03-24T21:11:00.397102Z","iopub.status.idle":"2022-03-24T21:11:11.910975Z","shell.execute_reply.started":"2022-03-24T21:11:00.397044Z","shell.execute_reply":"2022-03-24T21:11:11.909839Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2291da1a38344dda9b380bb90afad7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19825e61d8484f2798db7b8ac6c0cdd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9597f36e87984843ba50cb4acc7324a0"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:11:14.325666Z","iopub.execute_input":"2022-03-24T21:11:14.327136Z","iopub.status.idle":"2022-03-24T21:11:14.338077Z","shell.execute_reply.started":"2022-03-24T21:11:14.327027Z","shell.execute_reply":"2022-03-24T21:11:14.336758Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 4000\n    })\n    test: Dataset({\n        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 2000\n    })\n    validation: Dataset({\n        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"Фукнция для подсчёта метрик. ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n    acc = accuracy_score(labels, preds)\n    return {\n        'accuracy': acc,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall\n    }","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:11:16.941596Z","iopub.execute_input":"2022-03-24T21:11:16.943155Z","iopub.status.idle":"2022-03-24T21:11:16.952417Z","shell.execute_reply.started":"2022-03-24T21:11:16.943088Z","shell.execute_reply":"2022-03-24T21:11:16.949885Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Задаём нужные параметры дляя обучения моделей.","metadata":{}},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=2,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=10,\n    evaluation_strategy='epoch',\n    save_strategy='epoch',\n    load_best_model_at_end=True,\n    metric_for_best_model='eval_f1'\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:11:19.797590Z","iopub.execute_input":"2022-03-24T21:11:19.798466Z","iopub.status.idle":"2022-03-24T21:11:20.177078Z","shell.execute_reply.started":"2022-03-24T21:11:19.798420Z","shell.execute_reply":"2022-03-24T21:11:20.175987Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=8)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:11:22.817719Z","iopub.execute_input":"2022-03-24T21:11:22.818478Z","iopub.status.idle":"2022-03-24T21:11:22.826441Z","shell.execute_reply.started":"2022-03-24T21:11:22.818428Z","shell.execute_reply":"2022-03-24T21:11:22.824850Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from torch.nn import CrossEntropyLoss","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:11:26.065427Z","iopub.execute_input":"2022-03-24T21:11:26.066321Z","iopub.status.idle":"2022-03-24T21:11:26.070904Z","shell.execute_reply.started":"2022-03-24T21:11:26.066270Z","shell.execute_reply":"2022-03-24T21:11:26.069886Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### 1. SentimentClassifier","metadata":{}},{"cell_type":"markdown","source":"Немного видоизменённый класс SentimentClassifer с семинара. ","metadata":{}},{"cell_type":"code","source":"class SentimentClassifier(nn.Module):\n    \n    def __init__(self, n_classes):\n        super().__init__()\n        self.bert = AutoModel.from_pretrained(MODEL_NAME)\n        self.drop = nn.Dropout(p=0.3)\n        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n        self.n_classes = n_classes\n  \n    def forward(self, input_ids, attention_mask, labels=None):\n        last_hidden_state, pooled_output = self.bert(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            return_dict=False)\n       \n        logits = self.out(self.drop(pooled_output))\n\n        loss = None\n        if labels is not None:\n            loss_fn = nn.CrossEntropyLoss()\n            loss = loss_fn(logits.view(-1, self.n_classes), labels.view(-1))\n\n        output = (logits,)\n        return ((loss,) + output) if loss is not None else output","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:11:30.293886Z","iopub.execute_input":"2022-03-24T21:11:30.294617Z","iopub.status.idle":"2022-03-24T21:11:30.308669Z","shell.execute_reply.started":"2022-03-24T21:11:30.294573Z","shell.execute_reply":"2022-03-24T21:11:30.306847Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model = SentimentClassifier(2)\nmodel = model.to('cuda')","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:11:35.243309Z","iopub.execute_input":"2022-03-24T21:11:35.252048Z","iopub.status.idle":"2022-03-24T21:11:54.074140Z","shell.execute_reply.started":"2022-03-24T21:11:35.251934Z","shell.execute_reply":"2022-03-24T21:11:54.073078Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/111M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4040eebdd392460ebc7d90a927affe19"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at prajjwal1/bert-small were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Обучаем.","metadata":{}},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,                        \n    args=training_args,                  \n    train_dataset=tokenized_datasets['train'],         \n    eval_dataset=tokenized_datasets['validation'],           \n    compute_metrics=compute_metrics,\n    data_collator=data_collator,\n    tokenizer=tokenizer\n)\n\ntrainer_result = trainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:12:44.598967Z","iopub.execute_input":"2022-03-24T21:12:44.599357Z","iopub.status.idle":"2022-03-24T21:17:06.690706Z","shell.execute_reply.started":"2022-03-24T21:12:44.599319Z","shell.execute_reply":"2022-03-24T21:17:06.687345Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"The following columns in the training set  don't have a corresponding argument in `SentimentClassifier.forward` and have been ignored: text, token_type_ids.\n/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 4000\n  Num Epochs = 2\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 1\n  Total optimization steps = 1000\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.11"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20220324_211433-21fs6uk4</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/ddrodionova/huggingface/runs/21fs6uk4\" target=\"_blank\">./results</a></strong> to <a href=\"https://wandb.ai/ddrodionova/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1000/1000 02:23, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.323100</td>\n      <td>0.334828</td>\n      <td>0.871500</td>\n      <td>0.869211</td>\n      <td>0.884974</td>\n      <td>0.854000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.254000</td>\n      <td>0.354860</td>\n      <td>0.896500</td>\n      <td>0.896861</td>\n      <td>0.893744</td>\n      <td>0.900000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set  don't have a corresponding argument in `SentimentClassifier.forward` and have been ignored: text, token_type_ids.\n***** Running Evaluation *****\n  Num examples = 2000\n  Batch size = 8\nSaving model checkpoint to ./results/checkpoint-500\nTrainer.model is not a `PreTrainedModel`, only saving its state dict.\ntokenizer config file saved in ./results/checkpoint-500/tokenizer_config.json\nSpecial tokens file saved in ./results/checkpoint-500/special_tokens_map.json\nThe following columns in the evaluation set  don't have a corresponding argument in `SentimentClassifier.forward` and have been ignored: text, token_type_ids.\n***** Running Evaluation *****\n  Num examples = 2000\n  Batch size = 8\nSaving model checkpoint to ./results/checkpoint-1000\nTrainer.model is not a `PreTrainedModel`, only saving its state dict.\ntokenizer config file saved in ./results/checkpoint-1000/tokenizer_config.json\nSpecial tokens file saved in ./results/checkpoint-1000/special_tokens_map.json\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nLoading best model from ./results/checkpoint-1000 (score: 0.8968609865470851).\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer_result.metrics","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:17:09.716688Z","iopub.execute_input":"2022-03-24T21:17:09.717548Z","iopub.status.idle":"2022-03-24T21:17:09.729849Z","shell.execute_reply.started":"2022-03-24T21:17:09.717466Z","shell.execute_reply":"2022-03-24T21:17:09.728740Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'train_runtime': 260.9232,\n 'train_samples_per_second': 30.66,\n 'train_steps_per_second': 3.833,\n 'total_flos': 0.0,\n 'train_loss': 0.40278061163425444,\n 'epoch': 2.0}"},"metadata":{}}]},{"cell_type":"markdown","source":"Проверяем на данных из тестовой выборки.","metadata":{}},{"cell_type":"code","source":"tester_result = trainer.predict(test_dataset=tokenized_datasets['test'])","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:17:15.540109Z","iopub.execute_input":"2022-03-24T21:17:15.541353Z","iopub.status.idle":"2022-03-24T21:17:26.406922Z","shell.execute_reply.started":"2022-03-24T21:17:15.541290Z","shell.execute_reply":"2022-03-24T21:17:26.405826Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"The following columns in the test set  don't have a corresponding argument in `SentimentClassifier.forward` and have been ignored: text, token_type_ids.\n***** Running Prediction *****\n  Num examples = 2000\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [250/250 00:10]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"code","source":"tester_result.metrics","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:17:33.606347Z","iopub.execute_input":"2022-03-24T21:17:33.607303Z","iopub.status.idle":"2022-03-24T21:17:33.621269Z","shell.execute_reply.started":"2022-03-24T21:17:33.607256Z","shell.execute_reply":"2022-03-24T21:17:33.619618Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'test_loss': 0.44090044498443604,\n 'test_accuracy': 0.8775,\n 'test_f1': 0.8787728847105393,\n 'test_precision': 0.8697355533790402,\n 'test_recall': 0.888,\n 'test_runtime': 10.8429,\n 'test_samples_per_second': 184.453,\n 'test_steps_per_second': 23.057}"},"metadata":{}}]},{"cell_type":"markdown","source":"### 2. SentimentClassifier with CLS","metadata":{}},{"cell_type":"markdown","source":"Добавляем эмбеддинг [CLS] токенов с последнего слоя.","metadata":{}},{"cell_type":"code","source":"class SentimentClassifierCLS(nn.Module):\n    \n    def __init__(self, n_classes):\n        super().__init__()\n        self.bert = AutoModel.from_pretrained(MODEL_NAME)\n        self.drop = nn.Dropout(p=0.3)\n        self.out = nn.Linear(self.bert.config.hidden_size*2, n_classes)\n        self.n_classes = n_classes\n  \n    def forward(self, input_ids, attention_mask, labels=None):\n        last_hidden_state, pooled_output = self.bert(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            return_dict=False)\n       \n\n        cls = last_hidden_state[:,0,:] # [CLS]\n        stacked_layers = torch.hstack([cls, pooled_output])\n\n        logits = self.out(self.drop(stacked_layers))\n\n        loss = None\n        if labels is not None:\n            loss_fn = nn.CrossEntropyLoss()\n            loss = loss_fn(logits.view(-1, self.n_classes), labels.view(-1))\n\n        output = (logits,)\n        \n        return ((loss,) + output) if loss is not None else output","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:17:37.953801Z","iopub.execute_input":"2022-03-24T21:17:37.954257Z","iopub.status.idle":"2022-03-24T21:17:37.978008Z","shell.execute_reply.started":"2022-03-24T21:17:37.954212Z","shell.execute_reply":"2022-03-24T21:17:37.976971Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model = SentimentClassifierCLS(2)\nmodel = model.to('cpu')","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:17:40.826745Z","iopub.execute_input":"2022-03-24T21:17:40.827087Z","iopub.status.idle":"2022-03-24T21:17:43.282547Z","shell.execute_reply.started":"2022-03-24T21:17:40.827052Z","shell.execute_reply":"2022-03-24T21:17:43.280762Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"loading configuration file https://huggingface.co/prajjwal1/bert-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ac031779e2b4dd1d9da1e39c9d6a29fd45deea195eb3703a701d9c77f60abb4e.1257bb8f1f585038e86954d2560e36ca5c2dd98a8cde30fd22468940c911b672\nModel config BertConfig {\n  \"_name_or_path\": \"prajjwal1/bert-small\",\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 512,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 2048,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 8,\n  \"num_hidden_layers\": 4,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\nloading weights file https://huggingface.co/prajjwal1/bert-small/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/facfdb1638fdec899406e0efd5c2c43ae4bbafcb45dd15f68df1f2378e3e70fb.59547972ec02ba39d4ea413c843f1638e8f90e118a4334ae5d626bf7524ac597\nSome weights of the model checkpoint at prajjwal1/bert-small were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of BertModel were initialized from the model checkpoint at prajjwal1/bert-small.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Обучаем. ","metadata":{}},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,                        \n    args=training_args,                  \n    train_dataset=tokenized_datasets['train'],         \n    eval_dataset=tokenized_datasets['validation'],           \n    compute_metrics=compute_metrics,\n    data_collator=data_collator,\n    tokenizer=tokenizer\n)\n\ntrainer_result_cls = trainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:17:46.621512Z","iopub.execute_input":"2022-03-24T21:17:46.622731Z","iopub.status.idle":"2022-03-24T21:20:06.438367Z","shell.execute_reply.started":"2022-03-24T21:17:46.622674Z","shell.execute_reply":"2022-03-24T21:20:06.437675Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"The following columns in the training set  don't have a corresponding argument in `SentimentClassifierCLS.forward` and have been ignored: text, token_type_ids.\n/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 4000\n  Num Epochs = 2\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 1\n  Total optimization steps = 1000\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1000/1000 02:19, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.265700</td>\n      <td>0.339454</td>\n      <td>0.871500</td>\n      <td>0.870919</td>\n      <td>0.874874</td>\n      <td>0.867000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.169400</td>\n      <td>0.382169</td>\n      <td>0.887500</td>\n      <td>0.886764</td>\n      <td>0.892604</td>\n      <td>0.881000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set  don't have a corresponding argument in `SentimentClassifierCLS.forward` and have been ignored: text, token_type_ids.\n***** Running Evaluation *****\n  Num examples = 2000\n  Batch size = 8\nSaving model checkpoint to ./results/checkpoint-500\nTrainer.model is not a `PreTrainedModel`, only saving its state dict.\ntokenizer config file saved in ./results/checkpoint-500/tokenizer_config.json\nSpecial tokens file saved in ./results/checkpoint-500/special_tokens_map.json\nThe following columns in the evaluation set  don't have a corresponding argument in `SentimentClassifierCLS.forward` and have been ignored: text, token_type_ids.\n***** Running Evaluation *****\n  Num examples = 2000\n  Batch size = 8\nSaving model checkpoint to ./results/checkpoint-1000\nTrainer.model is not a `PreTrainedModel`, only saving its state dict.\ntokenizer config file saved in ./results/checkpoint-1000/tokenizer_config.json\nSpecial tokens file saved in ./results/checkpoint-1000/special_tokens_map.json\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nLoading best model from ./results/checkpoint-1000 (score: 0.886763965777554).\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer_result_cls.metrics","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:20:15.465170Z","iopub.execute_input":"2022-03-24T21:20:15.465430Z","iopub.status.idle":"2022-03-24T21:20:15.477641Z","shell.execute_reply.started":"2022-03-24T21:20:15.465403Z","shell.execute_reply":"2022-03-24T21:20:15.476866Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"{'train_runtime': 139.7181,\n 'train_samples_per_second': 57.258,\n 'train_steps_per_second': 7.157,\n 'total_flos': 0.0,\n 'train_loss': 0.4256142890453339,\n 'epoch': 2.0}"},"metadata":{}}]},{"cell_type":"markdown","source":"Проверяем на данных из тестовой выборки.","metadata":{}},{"cell_type":"code","source":"tester_result_cls = trainer.predict(test_dataset=tokenized_datasets['test'])","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:20:19.039855Z","iopub.execute_input":"2022-03-24T21:20:19.040108Z","iopub.status.idle":"2022-03-24T21:20:28.293904Z","shell.execute_reply.started":"2022-03-24T21:20:19.040081Z","shell.execute_reply":"2022-03-24T21:20:28.293211Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"The following columns in the test set  don't have a corresponding argument in `SentimentClassifierCLS.forward` and have been ignored: text, token_type_ids.\n***** Running Prediction *****\n  Num examples = 2000\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [250/250 00:09]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"code","source":"tester_result_cls.metrics","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:21:24.289866Z","iopub.execute_input":"2022-03-24T21:21:24.290120Z","iopub.status.idle":"2022-03-24T21:21:24.297507Z","shell.execute_reply.started":"2022-03-24T21:21:24.290093Z","shell.execute_reply":"2022-03-24T21:21:24.296819Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"{'test_loss': 0.4390011727809906,\n 'test_accuracy': 0.874,\n 'test_f1': 0.8738738738738739,\n 'test_precision': 0.874749498997996,\n 'test_recall': 0.873,\n 'test_runtime': 9.2433,\n 'test_samples_per_second': 216.372,\n 'test_steps_per_second': 27.047}"},"metadata":{}}]},{"cell_type":"markdown","source":"### 3. BertForSequenceClassification","metadata":{}},{"cell_type":"markdown","source":"Всё просто, скачиваем предобученный БЕРТ для классификации, аналогично обучаем и тестируем. ","metadata":{}},{"cell_type":"code","source":"from transformers import BertForSequenceClassification\n\nmodel = BertForSequenceClassification.from_pretrained(MODEL_NAME)\nmodel = model.to('cpu')","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:21:27.383913Z","iopub.execute_input":"2022-03-24T21:21:27.384174Z","iopub.status.idle":"2022-03-24T21:21:29.614868Z","shell.execute_reply.started":"2022-03-24T21:21:27.384140Z","shell.execute_reply":"2022-03-24T21:21:29.614083Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"loading configuration file https://huggingface.co/prajjwal1/bert-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ac031779e2b4dd1d9da1e39c9d6a29fd45deea195eb3703a701d9c77f60abb4e.1257bb8f1f585038e86954d2560e36ca5c2dd98a8cde30fd22468940c911b672\nModel config BertConfig {\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 512,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 2048,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 8,\n  \"num_hidden_layers\": 4,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\nloading weights file https://huggingface.co/prajjwal1/bert-small/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/facfdb1638fdec899406e0efd5c2c43ae4bbafcb45dd15f68df1f2378e3e70fb.59547972ec02ba39d4ea413c843f1638e8f90e118a4334ae5d626bf7524ac597\nSome weights of the model checkpoint at prajjwal1/bert-small were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-small and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,                        \n    args=training_args,                  \n    train_dataset=tokenized_datasets['train'],         \n    eval_dataset=tokenized_datasets['validation'],           \n    compute_metrics=compute_metrics,\n    data_collator=data_collator,\n    tokenizer=tokenizer\n)\n\ntrainer_result_pre = trainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:21:33.361689Z","iopub.execute_input":"2022-03-24T21:21:33.361952Z","iopub.status.idle":"2022-03-24T21:23:44.257693Z","shell.execute_reply.started":"2022-03-24T21:21:33.361924Z","shell.execute_reply":"2022-03-24T21:23:44.256998Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 4000\n  Num Epochs = 2\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 1\n  Total optimization steps = 1000\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1000/1000 02:10, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.282800</td>\n      <td>0.301622</td>\n      <td>0.879000</td>\n      <td>0.877654</td>\n      <td>0.887526</td>\n      <td>0.868000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.129500</td>\n      <td>0.388723</td>\n      <td>0.890000</td>\n      <td>0.891304</td>\n      <td>0.880859</td>\n      <td>0.902000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n***** Running Evaluation *****\n  Num examples = 2000\n  Batch size = 8\nSaving model checkpoint to ./results/checkpoint-500\nConfiguration saved in ./results/checkpoint-500/config.json\nModel weights saved in ./results/checkpoint-500/pytorch_model.bin\ntokenizer config file saved in ./results/checkpoint-500/tokenizer_config.json\nSpecial tokens file saved in ./results/checkpoint-500/special_tokens_map.json\nThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n***** Running Evaluation *****\n  Num examples = 2000\n  Batch size = 8\nSaving model checkpoint to ./results/checkpoint-1000\nConfiguration saved in ./results/checkpoint-1000/config.json\nModel weights saved in ./results/checkpoint-1000/pytorch_model.bin\ntokenizer config file saved in ./results/checkpoint-1000/tokenizer_config.json\nSpecial tokens file saved in ./results/checkpoint-1000/special_tokens_map.json\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nLoading best model from ./results/checkpoint-1000 (score: 0.8913043478260869).\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer_result_pre.metrics","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:23:47.043115Z","iopub.execute_input":"2022-03-24T21:23:47.043376Z","iopub.status.idle":"2022-03-24T21:23:47.051337Z","shell.execute_reply.started":"2022-03-24T21:23:47.043350Z","shell.execute_reply":"2022-03-24T21:23:47.050585Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"{'train_runtime': 130.8263,\n 'train_samples_per_second': 61.15,\n 'train_steps_per_second': 7.644,\n 'total_flos': 316397371392000.0,\n 'train_loss': 0.3838183356523514,\n 'epoch': 2.0}"},"metadata":{}}]},{"cell_type":"code","source":"tester_results_pre = trainer.predict(test_dataset=tokenized_datasets['test'])","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:23:49.850851Z","iopub.execute_input":"2022-03-24T21:23:49.851330Z","iopub.status.idle":"2022-03-24T21:23:59.761683Z","shell.execute_reply.started":"2022-03-24T21:23:49.851280Z","shell.execute_reply":"2022-03-24T21:23:59.760974Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n***** Running Prediction *****\n  Num examples = 2000\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [250/250 00:09]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"code","source":"tester_results_pre.metrics","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:25:24.669455Z","iopub.execute_input":"2022-03-24T21:25:24.669964Z","iopub.status.idle":"2022-03-24T21:25:24.676584Z","shell.execute_reply.started":"2022-03-24T21:25:24.669931Z","shell.execute_reply":"2022-03-24T21:25:24.675754Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"{'test_loss': 0.46258434653282166,\n 'test_accuracy': 0.874,\n 'test_f1': 0.8771929824561403,\n 'test_precision': 0.8555133079847909,\n 'test_recall': 0.9,\n 'test_runtime': 9.894,\n 'test_samples_per_second': 202.142,\n 'test_steps_per_second': 25.268}"},"metadata":{}}]},{"cell_type":"markdown","source":"### 4. SentimentClassifier with CLS tokens from all layers","metadata":{}},{"cell_type":"markdown","source":"Агрегируем [CLS] токены для всех слоёв и находим среднее.","metadata":{}},{"cell_type":"code","source":"class SentimentClassifierPooledCLS(nn.Module):\n    def __init__(self, n_classes):\n        super().__init__()\n        self.n_classes = n_classes\n        self.bert = AutoModel.from_pretrained(MODEL_NAME)\n        self.drop = nn.Dropout(p=0.3)\n        self.out = nn.Linear(self.bert.config.hidden_size*2, n_classes)\n  \n    def forward(self, input_ids, attention_mask, labels=None):\n        _, pooled_output, hidden_states = self.bert(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            return_dict=False,\n            output_hidden_states=True)\n       \n        hidden_states = torch.stack(hidden_states)\n        hidden_cls = hidden_states[:,:,1,:]\n        hidden_cls = hidden_cls.mean(axis=0)\n\n        stacked_layers = torch.hstack([hidden_cls, pooled_output])\n\n        logits = self.out(self.drop(stacked_layers))\n\n        loss = None\n        if labels is not None:\n            loss_fn = nn.CrossEntropyLoss()\n            loss = loss_fn(logits.view(-1, self.n_classes), labels.view(-1))\n\n        output = (logits,)\n        return ((loss,) + output) if loss is not None else output","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:25:31.538979Z","iopub.execute_input":"2022-03-24T21:25:31.539700Z","iopub.status.idle":"2022-03-24T21:25:31.552133Z","shell.execute_reply.started":"2022-03-24T21:25:31.539652Z","shell.execute_reply":"2022-03-24T21:25:31.551545Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model = SentimentClassifierPooledCLS(2)\nmodel = model.to('cpu')","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:25:34.214752Z","iopub.execute_input":"2022-03-24T21:25:34.215406Z","iopub.status.idle":"2022-03-24T21:25:36.434343Z","shell.execute_reply.started":"2022-03-24T21:25:34.215370Z","shell.execute_reply":"2022-03-24T21:25:36.433658Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"loading configuration file https://huggingface.co/prajjwal1/bert-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ac031779e2b4dd1d9da1e39c9d6a29fd45deea195eb3703a701d9c77f60abb4e.1257bb8f1f585038e86954d2560e36ca5c2dd98a8cde30fd22468940c911b672\nModel config BertConfig {\n  \"_name_or_path\": \"prajjwal1/bert-small\",\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 512,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 2048,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 8,\n  \"num_hidden_layers\": 4,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\nloading weights file https://huggingface.co/prajjwal1/bert-small/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/facfdb1638fdec899406e0efd5c2c43ae4bbafcb45dd15f68df1f2378e3e70fb.59547972ec02ba39d4ea413c843f1638e8f90e118a4334ae5d626bf7524ac597\nSome weights of the model checkpoint at prajjwal1/bert-small were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of BertModel were initialized from the model checkpoint at prajjwal1/bert-small.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets['train'],\n    eval_dataset=tokenized_datasets['validation'],\n    compute_metrics=compute_metrics,\n    data_collator=data_collator,\n    tokenizer=tokenizer\n)\n\ntrainer_results_pooled = trainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:25:39.392122Z","iopub.execute_input":"2022-03-24T21:25:39.392597Z","iopub.status.idle":"2022-03-24T21:27:46.490027Z","shell.execute_reply.started":"2022-03-24T21:25:39.392562Z","shell.execute_reply":"2022-03-24T21:27:46.489307Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"The following columns in the training set  don't have a corresponding argument in `SentimentClassifierPooledCLS.forward` and have been ignored: text, token_type_ids.\n/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 4000\n  Num Epochs = 2\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 1\n  Total optimization steps = 1000\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1000/1000 02:06, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.261200</td>\n      <td>0.346265</td>\n      <td>0.862000</td>\n      <td>0.858896</td>\n      <td>0.878661</td>\n      <td>0.840000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.234400</td>\n      <td>0.378114</td>\n      <td>0.887000</td>\n      <td>0.885859</td>\n      <td>0.894898</td>\n      <td>0.877000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set  don't have a corresponding argument in `SentimentClassifierPooledCLS.forward` and have been ignored: text, token_type_ids.\n***** Running Evaluation *****\n  Num examples = 2000\n  Batch size = 8\nSaving model checkpoint to ./results/checkpoint-500\nTrainer.model is not a `PreTrainedModel`, only saving its state dict.\ntokenizer config file saved in ./results/checkpoint-500/tokenizer_config.json\nSpecial tokens file saved in ./results/checkpoint-500/special_tokens_map.json\nThe following columns in the evaluation set  don't have a corresponding argument in `SentimentClassifierPooledCLS.forward` and have been ignored: text, token_type_ids.\n***** Running Evaluation *****\n  Num examples = 2000\n  Batch size = 8\nSaving model checkpoint to ./results/checkpoint-1000\nTrainer.model is not a `PreTrainedModel`, only saving its state dict.\ntokenizer config file saved in ./results/checkpoint-1000/tokenizer_config.json\nSpecial tokens file saved in ./results/checkpoint-1000/special_tokens_map.json\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nLoading best model from ./results/checkpoint-1000 (score: 0.8858585858585859).\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer_results_pooled.metrics","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:28:12.436332Z","iopub.execute_input":"2022-03-24T21:28:12.437090Z","iopub.status.idle":"2022-03-24T21:28:12.445170Z","shell.execute_reply.started":"2022-03-24T21:28:12.437046Z","shell.execute_reply":"2022-03-24T21:28:12.444542Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"{'train_runtime': 127.0275,\n 'train_samples_per_second': 62.978,\n 'train_steps_per_second': 7.872,\n 'total_flos': 0.0,\n 'train_loss': 0.43764497292041776,\n 'epoch': 2.0}"},"metadata":{}}]},{"cell_type":"code","source":"tester_results_pooled = trainer.predict(test_dataset=tokenized_datasets['test'])","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:28:15.053555Z","iopub.execute_input":"2022-03-24T21:28:15.053941Z","iopub.status.idle":"2022-03-24T21:28:24.328781Z","shell.execute_reply.started":"2022-03-24T21:28:15.053909Z","shell.execute_reply":"2022-03-24T21:28:24.328125Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"The following columns in the test set  don't have a corresponding argument in `SentimentClassifierPooledCLS.forward` and have been ignored: text, token_type_ids.\n***** Running Prediction *****\n  Num examples = 2000\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [250/250 00:09]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"code","source":"tester_results_pooled.metrics","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:28:26.793545Z","iopub.execute_input":"2022-03-24T21:28:26.793934Z","iopub.status.idle":"2022-03-24T21:28:26.808093Z","shell.execute_reply.started":"2022-03-24T21:28:26.793903Z","shell.execute_reply":"2022-03-24T21:28:26.807360Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"{'test_loss': 0.4512108564376831,\n 'test_accuracy': 0.8695,\n 'test_f1': 0.869172932330827,\n 'test_precision': 0.871356783919598,\n 'test_recall': 0.867,\n 'test_runtime': 9.2646,\n 'test_samples_per_second': 215.874,\n 'test_steps_per_second': 26.984}"},"metadata":{}}]},{"cell_type":"markdown","source":"### Model Comparison","metadata":{}},{"cell_type":"markdown","source":"1. <b>SentimentClassifier: 0.8787</b>\n2. SentimentClassifier with CSL: 0.8738\n3. BertForSequenceClassification: 0.8771\n4. SentimentClassifier with CLS tokens from all layers: 0.8691","metadata":{}},{"cell_type":"markdown","source":"В целом все модели показали достаточно высокие результаты. Интересно, что лучшие результаты показала самая первая модель.","metadata":{}},{"cell_type":"markdown","source":"# GooglePlay Reviews","metadata":{}},{"cell_type":"markdown","source":"Посмотрим, как работает последняя модель на отзывах из GooglePlay.","metadata":{}},{"cell_type":"code","source":"! pip install gdown","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:32:36.404553Z","iopub.execute_input":"2022-03-24T21:32:36.405022Z","iopub.status.idle":"2022-03-24T21:33:01.110352Z","shell.execute_reply.started":"2022-03-24T21:32:36.404991Z","shell.execute_reply":"2022-03-24T21:33:01.109546Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting gdown\n  Downloading gdown-4.4.0.tar.gz (14 kB)\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.26.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown) (4.10.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.6.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.62.3)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.3.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2021.10.8)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (3.1)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.0.9)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\nBuilding wheels for collected packages: gdown\n  Building wheel for gdown (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14775 sha256=4e253c3d8fffdd7fdab50fd7ba8a99bce2c29c3dbc6df4c63ae8f193f3a4aa79\n  Stored in directory: /root/.cache/pip/wheels/fb/c3/0e/c4d8ff8bfcb0461afff199471449f642179b74968c15b7a69c\nSuccessfully built gdown\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.4.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"! gdown --id 1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:33:38.643135Z","iopub.execute_input":"2022-03-24T21:33:38.643386Z","iopub.status.idle":"2022-03-24T21:33:44.364711Z","shell.execute_reply.started":"2022-03-24T21:33:38.643358Z","shell.execute_reply":"2022-03-24T21:33:44.363872Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n/opt/conda/lib/python3.7/site-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  category=FutureWarning,\nDownloading...\nFrom: https://drive.google.com/uc?id=1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv\nTo: /kaggle/working/reviews.csv\n100%|██████████████████████████████████████| 7.17M/7.17M [00:00<00:00, 71.7MB/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Посмотрим на датасет с отзывами. ","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('reviews.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:33:48.526577Z","iopub.execute_input":"2022-03-24T21:33:48.526859Z","iopub.status.idle":"2022-03-24T21:33:48.682719Z","shell.execute_reply.started":"2022-03-24T21:33:48.526832Z","shell.execute_reply":"2022-03-24T21:33:48.682035Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"                userName                                          userImage  \\\n0          Andrew Thomas  https://lh3.googleusercontent.com/a-/AOh14GiHd...   \n1           Craig Haines  https://lh3.googleusercontent.com/-hoe0kwSJgPQ...   \n2          steven adkins  https://lh3.googleusercontent.com/a-/AOh14GiXw...   \n3       Lars Panzerbjørn  https://lh3.googleusercontent.com/a-/AOh14Gg-h...   \n4          Scott Prewitt  https://lh3.googleusercontent.com/-K-X1-YsVd6U...   \n...                  ...                                                ...   \n15741          Tammy Kay  https://lh3.googleusercontent.com/a-/AOh14GhYP...   \n15742          Ysm Johan  https://lh3.googleusercontent.com/a-/AOh14Ggmd...   \n15743      casey dearden  https://lh3.googleusercontent.com/a-/AOh14Gg2U...   \n15744     Jerry G Tamate  https://lh3.googleusercontent.com/a-/AOh14GiTP...   \n15745  Ahmed elsalamouni  https://lh3.googleusercontent.com/-9QSxVUhCoDI...   \n\n                                                 content  score  \\\n0      Update: After getting a response from the deve...      1   \n1      Used it for a fair amount of time without any ...      1   \n2      Your app sucks now!!!!! Used to be good but no...      1   \n3      It seems OK, but very basic. Recurring tasks n...      1   \n4      Absolutely worthless. This app runs a prohibit...      1   \n...                                                  ...    ...   \n15741  I believe that this is by far the best app wit...      5   \n15742                       It sometimes crashes a lot!!      5   \n15743                         Works well for what I need      5   \n15744                                           Love it.      5   \n15745  Really amazing and helped me sooo much just i ...      5   \n\n       thumbsUpCount reviewCreatedVersion                   at  \\\n0                 21             4.17.0.3  2020-04-05 22:25:57   \n1                 11             4.17.0.3  2020-04-04 13:40:01   \n2                 17             4.17.0.3  2020-04-01 16:18:13   \n3                192             4.17.0.2  2020-03-12 08:17:34   \n4                 42             4.17.0.2  2020-03-14 17:41:01   \n...              ...                  ...                  ...   \n15741              0                  NaN  2018-02-17 06:09:03   \n15742              0                4.3.7  2018-02-15 10:45:22   \n15743              0                4.3.7  2018-02-09 18:40:37   \n15744              0                  NaN  2018-02-06 12:36:17   \n15745              6                4.3.7  2018-02-04 22:57:09   \n\n                                            replyContent            repliedAt  \\\n0      According to our TOS, and the term you have ag...  2020-04-05 15:10:24   \n1      It sounds like you logged in with a different ...  2020-04-05 15:11:35   \n2      This sounds odd! We are not aware of any issue...  2020-04-02 16:05:56   \n3      We do offer this option as part of the Advance...  2020-03-15 06:20:13   \n4      We're sorry you feel this way! 90% of the app ...  2020-03-15 23:45:51   \n...                                                  ...                  ...   \n15741                                                NaN                  NaN   \n15742                                                NaN                  NaN   \n15743                                                NaN                  NaN   \n15744                                                NaN                  NaN   \n15745                                                NaN                  NaN   \n\n           sortOrder              appId  \n0      most_relevant          com.anydo  \n1      most_relevant          com.anydo  \n2      most_relevant          com.anydo  \n3      most_relevant          com.anydo  \n4      most_relevant          com.anydo  \n...              ...                ...  \n15741         newest  com.appxy.planner  \n15742         newest  com.appxy.planner  \n15743         newest  com.appxy.planner  \n15744         newest  com.appxy.planner  \n15745         newest  com.appxy.planner  \n\n[15746 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userName</th>\n      <th>userImage</th>\n      <th>content</th>\n      <th>score</th>\n      <th>thumbsUpCount</th>\n      <th>reviewCreatedVersion</th>\n      <th>at</th>\n      <th>replyContent</th>\n      <th>repliedAt</th>\n      <th>sortOrder</th>\n      <th>appId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Andrew Thomas</td>\n      <td>https://lh3.googleusercontent.com/a-/AOh14GiHd...</td>\n      <td>Update: After getting a response from the deve...</td>\n      <td>1</td>\n      <td>21</td>\n      <td>4.17.0.3</td>\n      <td>2020-04-05 22:25:57</td>\n      <td>According to our TOS, and the term you have ag...</td>\n      <td>2020-04-05 15:10:24</td>\n      <td>most_relevant</td>\n      <td>com.anydo</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Craig Haines</td>\n      <td>https://lh3.googleusercontent.com/-hoe0kwSJgPQ...</td>\n      <td>Used it for a fair amount of time without any ...</td>\n      <td>1</td>\n      <td>11</td>\n      <td>4.17.0.3</td>\n      <td>2020-04-04 13:40:01</td>\n      <td>It sounds like you logged in with a different ...</td>\n      <td>2020-04-05 15:11:35</td>\n      <td>most_relevant</td>\n      <td>com.anydo</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>steven adkins</td>\n      <td>https://lh3.googleusercontent.com/a-/AOh14GiXw...</td>\n      <td>Your app sucks now!!!!! Used to be good but no...</td>\n      <td>1</td>\n      <td>17</td>\n      <td>4.17.0.3</td>\n      <td>2020-04-01 16:18:13</td>\n      <td>This sounds odd! We are not aware of any issue...</td>\n      <td>2020-04-02 16:05:56</td>\n      <td>most_relevant</td>\n      <td>com.anydo</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lars Panzerbjørn</td>\n      <td>https://lh3.googleusercontent.com/a-/AOh14Gg-h...</td>\n      <td>It seems OK, but very basic. Recurring tasks n...</td>\n      <td>1</td>\n      <td>192</td>\n      <td>4.17.0.2</td>\n      <td>2020-03-12 08:17:34</td>\n      <td>We do offer this option as part of the Advance...</td>\n      <td>2020-03-15 06:20:13</td>\n      <td>most_relevant</td>\n      <td>com.anydo</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Scott Prewitt</td>\n      <td>https://lh3.googleusercontent.com/-K-X1-YsVd6U...</td>\n      <td>Absolutely worthless. This app runs a prohibit...</td>\n      <td>1</td>\n      <td>42</td>\n      <td>4.17.0.2</td>\n      <td>2020-03-14 17:41:01</td>\n      <td>We're sorry you feel this way! 90% of the app ...</td>\n      <td>2020-03-15 23:45:51</td>\n      <td>most_relevant</td>\n      <td>com.anydo</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15741</th>\n      <td>Tammy Kay</td>\n      <td>https://lh3.googleusercontent.com/a-/AOh14GhYP...</td>\n      <td>I believe that this is by far the best app wit...</td>\n      <td>5</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>2018-02-17 06:09:03</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>newest</td>\n      <td>com.appxy.planner</td>\n    </tr>\n    <tr>\n      <th>15742</th>\n      <td>Ysm Johan</td>\n      <td>https://lh3.googleusercontent.com/a-/AOh14Ggmd...</td>\n      <td>It sometimes crashes a lot!!</td>\n      <td>5</td>\n      <td>0</td>\n      <td>4.3.7</td>\n      <td>2018-02-15 10:45:22</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>newest</td>\n      <td>com.appxy.planner</td>\n    </tr>\n    <tr>\n      <th>15743</th>\n      <td>casey dearden</td>\n      <td>https://lh3.googleusercontent.com/a-/AOh14Gg2U...</td>\n      <td>Works well for what I need</td>\n      <td>5</td>\n      <td>0</td>\n      <td>4.3.7</td>\n      <td>2018-02-09 18:40:37</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>newest</td>\n      <td>com.appxy.planner</td>\n    </tr>\n    <tr>\n      <th>15744</th>\n      <td>Jerry G Tamate</td>\n      <td>https://lh3.googleusercontent.com/a-/AOh14GiTP...</td>\n      <td>Love it.</td>\n      <td>5</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>2018-02-06 12:36:17</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>newest</td>\n      <td>com.appxy.planner</td>\n    </tr>\n    <tr>\n      <th>15745</th>\n      <td>Ahmed elsalamouni</td>\n      <td>https://lh3.googleusercontent.com/-9QSxVUhCoDI...</td>\n      <td>Really amazing and helped me sooo much just i ...</td>\n      <td>5</td>\n      <td>6</td>\n      <td>4.3.7</td>\n      <td>2018-02-04 22:57:09</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>newest</td>\n      <td>com.appxy.planner</td>\n    </tr>\n  </tbody>\n</table>\n<p>15746 rows × 11 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"negative_review = df[df.score<=2]","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:33:55.048936Z","iopub.execute_input":"2022-03-24T21:33:55.049341Z","iopub.status.idle":"2022-03-24T21:33:55.063492Z","shell.execute_reply.started":"2022-03-24T21:33:55.049308Z","shell.execute_reply":"2022-03-24T21:33:55.062654Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"negative_review.content[3]","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:33:57.105779Z","iopub.execute_input":"2022-03-24T21:33:57.106049Z","iopub.status.idle":"2022-03-24T21:33:57.118004Z","shell.execute_reply.started":"2022-03-24T21:33:57.106019Z","shell.execute_reply":"2022-03-24T21:33:57.117350Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"\"It seems OK, but very basic. Recurring tasks need some work to be actually useful. For example, it would be nice to be able to set a task to be recurring on the first of every month, without only being able to set that up on the first of the month. Edit; I also just noticed that there is no dark theme. Both may be available as paid for options, but I'll never know, since they are basic options and without them, I have no reason to try this app, and thus will never pay for actual premium options.\""},"metadata":{}}]},{"cell_type":"code","source":"negative = '''It seems OK, but very basic. Recurring tasks need \nsome work to be actually useful. \nFor example, it would be nice to be able to set a task to be recurring on the first of every month, \nwithout only being able to set that up on the first of the month. \nEdit; I also just noticed that there is no dark theme. \nBoth may be available as paid for options, but I'll never know, \nsince they are basic options and without them, \nI have no reason to try this app, and thus will never pay for actual premium options.'''\n\nencoding = tokenizer.encode_plus(\n  negative,\n  max_length=512,\n  add_special_tokens=True, \n  return_token_type_ids=True,\n  padding='max_length',\n  return_attention_mask=True,\n  return_tensors='pt',  \n  truncation=True\n).to('cuda')","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:33:59.849519Z","iopub.execute_input":"2022-03-24T21:33:59.849777Z","iopub.status.idle":"2022-03-24T21:33:59.860591Z","shell.execute_reply.started":"2022-03-24T21:33:59.849749Z","shell.execute_reply":"2022-03-24T21:33:59.859889Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"model(\n  input_ids=encoding['input_ids'], \n  attention_mask=encoding['attention_mask'])[0].cpu().detach().numpy().argmax()","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:34:03.447959Z","iopub.execute_input":"2022-03-24T21:34:03.448211Z","iopub.status.idle":"2022-03-24T21:34:03.473636Z","shell.execute_reply.started":"2022-03-24T21:34:03.448184Z","shell.execute_reply":"2022-03-24T21:34:03.472853Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"Отрицательная полярность для отрицательного отзыва. ","metadata":{}},{"cell_type":"code","source":"neutral_review = df[df.score==3]","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:34:05.810927Z","iopub.execute_input":"2022-03-24T21:34:05.811178Z","iopub.status.idle":"2022-03-24T21:34:05.818223Z","shell.execute_reply.started":"2022-03-24T21:34:05.811150Z","shell.execute_reply":"2022-03-24T21:34:05.817508Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"neutral_review.content[400]","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:34:07.301294Z","iopub.execute_input":"2022-03-24T21:34:07.301870Z","iopub.status.idle":"2022-03-24T21:34:07.314288Z","shell.execute_reply.started":"2022-03-24T21:34:07.301833Z","shell.execute_reply":"2022-03-24T21:34:07.313500Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"\"I love the concept of the app I'm just not digging the functionality. Trying to set a custom date and time is a complete pain in the you know what. Every time I select pm it's stays at am. I have to do it multiple times before it catches. Same issue with the clock. I try to rotate the dial to select an hour and it hangs and throws me over to minutes. I go back to hours and it does the same thing. I finally just gave up. Back to the old string around the finger. ☹️\""},"metadata":{}}]},{"cell_type":"code","source":"neutral = '''I love the concept of the app I'm just not digging the functionality. \nTrying to set a custom date and time is a complete pain in the you know what. \nEvery time I select pm it's stays at am. I have to do it multiple \ntimes before it catches. Same issue with the clock. \nI try to rotate the dial to select an hour and it hangs and \nthrows me over to minutes. I go back to hours and it does the same thing. \nI finally just gave up. Back to the old string around the finger. ☹️'''\n\nencoding = tokenizer.encode_plus(\n  neutral,\n  max_length=512,\n  add_special_tokens=True, \n  return_token_type_ids=True,\n  padding='max_length',\n  return_attention_mask=True,\n  return_tensors='pt',  \n  truncation=True\n).to('cuda')","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:34:09.412015Z","iopub.execute_input":"2022-03-24T21:34:09.412267Z","iopub.status.idle":"2022-03-24T21:34:09.422631Z","shell.execute_reply.started":"2022-03-24T21:34:09.412240Z","shell.execute_reply":"2022-03-24T21:34:09.421297Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"model(\n  input_ids=encoding['input_ids'], \n  attention_mask=encoding['attention_mask'])[0].cpu().detach().numpy().argmax()","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:34:12.188830Z","iopub.execute_input":"2022-03-24T21:34:12.189637Z","iopub.status.idle":"2022-03-24T21:34:12.220802Z","shell.execute_reply.started":"2022-03-24T21:34:12.189594Z","shell.execute_reply":"2022-03-24T21:34:12.220161Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"markdown","source":"Положительная полярность для нейтральной оценки.","metadata":{}},{"cell_type":"code","source":"positive_review = df[df.score>3]","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:34:14.300399Z","iopub.execute_input":"2022-03-24T21:34:14.300970Z","iopub.status.idle":"2022-03-24T21:34:14.311842Z","shell.execute_reply.started":"2022-03-24T21:34:14.300935Z","shell.execute_reply":"2022-03-24T21:34:14.309434Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"positive_review.content[15741]","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:34:16.277053Z","iopub.execute_input":"2022-03-24T21:34:16.277299Z","iopub.status.idle":"2022-03-24T21:34:16.287062Z","shell.execute_reply.started":"2022-03-24T21:34:16.277272Z","shell.execute_reply":"2022-03-24T21:34:16.285976Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"\"I believe that this is by far the best app with helping ppl keep track of a lot of daily task and reminders. It's easy to function understand & it syncs with my Google calendar which is an A+ in my book.\""},"metadata":{}}]},{"cell_type":"code","source":"positive = '''I believe that this is by far the best app with helping \nppl keep track of a lot of daily task and reminders. \nIt's easy to function understand & it syncs with my Google calendar which is an A+ in my book.'''\n\nencoding = tokenizer.encode_plus(\n  positive,\n  max_length=512,\n  add_special_tokens=True, \n  return_token_type_ids=True,\n  padding='max_length',\n  return_attention_mask=True,\n  return_tensors='pt',  \n  truncation=True\n).to('cuda')","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:34:18.390344Z","iopub.execute_input":"2022-03-24T21:34:18.390898Z","iopub.status.idle":"2022-03-24T21:34:18.402180Z","shell.execute_reply.started":"2022-03-24T21:34:18.390862Z","shell.execute_reply":"2022-03-24T21:34:18.401215Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"model(\n  input_ids=encoding['input_ids'], \n  attention_mask=encoding['attention_mask'])[0].cpu().detach().numpy().argmax()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:34:21.011783Z","iopub.execute_input":"2022-03-24T21:34:21.012036Z","iopub.status.idle":"2022-03-24T21:34:21.028602Z","shell.execute_reply.started":"2022-03-24T21:34:21.012010Z","shell.execute_reply":"2022-03-24T21:34:21.027920Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"markdown","source":"Положительная полярность для положительного отзыва. ","metadata":{}},{"cell_type":"markdown","source":"В целом модель работает корректно, пусть и отзывы рассчитаны на 3 класса.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
